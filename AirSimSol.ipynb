{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#AirSimSol"
      ],
      "metadata": {
        "id": "YjO82CvI6ufj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import time\n",
        "the same thing but with ppo algorithim import numpy as np\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "import random\n",
        "import copy\n",
        "import math\n",
        "\n",
        "import roslib\n",
        "import rospy\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from std_srvs.srv import Empty as empty\n",
        "from std_msgs.msg import Empty\n",
        "from gazebo_msgs.srv import SetModelConfiguration\n",
        "\n",
        "from control_msgs.msg import JointControllerState\n",
        "from sensor_msgs.msg import JointState\n",
        "from gazebo_msgs.msg import LinkStates\n",
        "from std_msgs.msg import Float64\n",
        "from std_msgs.msg import String\n",
        "from nav_msgs.msg import Odometry\n",
        "from geometry_msgs.msg import Twist\n",
        "from ardrone_autonomy.msg import Navdata\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = DummyVecEnv(\n",
        "        [\n",
        "            lambda: Monitor(\n",
        "                gym.make(\n",
        "                    \"CartPole-v1\",  # Use a predefined gym environment like CartPole\n",
        "                )\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",  # MlpPolicy is generally used for environments like CartPole\n",
        "        env,\n",
        "        learning_rate=0.00025,\n",
        "        verbose=2,\n",
        "        batch_size=512,\n",
        "        max_grad_norm=0.5,\n",
        "        device=\"cuda\",\n",
        "        tensorboard_log=None,\n",
        "    )\n",
        "\n",
        "    callbacks = []\n",
        "    eval_callback = EvalCallback(\n",
        "        env,\n",
        "        callback_on_new_best=None,\n",
        "        n_eval_episodes=5,\n",
        "        best_model_save_path=\".\",\n",
        "        log_path=\".\",\n",
        "        eval_freq=10000,\n",
        "    )\n",
        "    callbacks.append(eval_callback)\n",
        "\n",
        "    model.learn(\n",
        "        total_timesteps=int(5e5),\n",
        "        tb_log_name=\"cartpole_run_\" + str(time.time()),\n",
        "        callback=callbacks\n",
        "    )\n",
        "\n",
        "    # Save policy weights\n",
        "    model.save(\"cartpole_policy\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "43aDmF8I_6_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}